version: "3.3"
services:
  mbaza-tts-eng-gpu:
    container_name: mbaza-tts-eng-gpu
    restart: unless-stopped
    env_file:
      - .env
    build:
      context: ./
      dockerfile: Dockerfile-eng-gpu
      labels:
        - mbaza-tts-eng-gpu
    ports:
      - "6902:6902"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: [ '1' ] # Defaults to second gpu, it should be "0" for a server with just one gpu.
              capabilities: [ gpu ]
    environment:
      - THREADS=2
      - PROCESSES=1 # allow 2250 MB /x1 worker
      - TIMEOUT=240 # worker timeout
      - GRACEFUL_TIMEOUT=220 # worker timeout
      - SRV_HOST=0.0.0.0
      - SRV_PORT=6902
      - APP_LANG=eng
      - APP_SENTENCE_MAX_WORDS=40
      - APP_SENTENCE_INFER_BATCH_SIZE=3 # allow around 550MB /x1 APP_SENTENCE_INFER_BATCH_SIZE
      - APP_SAMPLE_TEXT=. This is a sample input text .
      - APP_LOG_LEVEL=debug

#  mbaza-tts-caddy:
#    image: caddy:2-alpine
#    container_name: mbaza-tts-caddy
#    restart: unless-stopped
#    env_file:
#      - .env
#    ports:
#      - "5002:5002"
#    environment:
#      - PROXY_TARGET=mbaza-tts-eng-gpu:6901
#    volumes:
#      - $PWD/Caddyfile:/etc/caddy/Caddyfile
#      - caddy_data:/data
#      - caddy_config:/config
#    depends_on:
#      - mbaza-tts-eng-gpu
#
#volumes:
#  caddy_data:
#    external: true
#  caddy_config:
